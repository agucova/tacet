# v5.2 Mixture Prior: Correlation-Induced Failure Mode

**Date**: 2025-01-18
**Status**: Issue Report for Spec Developers
**Affected**: Spec v5.2 mixture prior (narrow + slab components)

## Executive Summary

The v5.2 mixture prior fails to detect large effects when the likelihood covariance matrix has high inter-decile correlations. With the SILENT web application dataset (effect ≈ 13,000 ns, θ = 100 ns), we observe:

| Covariance Type | P(leak) | Expected |
|-----------------|---------|----------|
| Diagonal (regression test) | **100%** | >99% |
| Correlated (bootstrap) | **61%** | >99% |

The 61% equals the prior exceedance rate, indicating the data is not informing the posterior.

## Problem Description

### Setup

- **Dataset**: SILENT web application (`web-diff-lan-10k.csv`)
- **Observed effect**: Δ ≈ [10366, 13156, 13296, 12800, 11741, 12936, 13215, 11804, 18715] ns
- **Threshold**: θ = 100 ns (AdjacentNetwork)
- **Sample size**: n = 10,000 per class

### What We Observe

When using bootstrap-estimated covariance (which has correlations):

```
sigma diagonal = [7.46e6, 7.82e6, 6.82e6, ..., 6.57e7]
sigma correlations: r(0,1) = 0.769, r(0,8) = 0.288

sigma_narrow = 80 ns, sigma_slab = 27962 ns
prior_narrow diag = [6.41e3, ...], prior_slab diag = [7.82e8, ...]

log_ml_narrow = -91.90  ← HIGHER (better)
log_ml_slab = -95.44    ← LOWER (worse)

narrow_weight_post = 0.9997
slab_weight_post = 0.0003

P(leak) = 62.6%  ← Should be >99%
```

The narrow component dominates despite the observed effect being 130× the threshold.

## Root Cause Analysis

### The Marginal Likelihood Computation

For each component, the log marginal likelihood is:

```
log p(Δ | component) = -0.5 × (9·log(2π) + log|A| + Δ'A⁻¹Δ)
```

where A = Σ_n + Λ₀ (likelihood covariance + prior covariance).

### Breakdown by Component

**Narrow component** (Λ_narrow ≪ Σ_n, so A ≈ Σ_n):
- log|A| ≈ log|Σ_n| = 136.15
- Δ'A⁻¹Δ ≈ Δ'Σ_n⁻¹Δ = **31.12** ← This is the problem!
- log_ml = -0.5 × (16.5 + 136.15 + 31.12) = **-91.9**

**Slab component** (Λ_slab ≫ Σ_n, so A ≈ Λ_slab):
- log|A| ≈ log|Λ_slab| = 173.77
- Δ'A⁻¹Δ ≈ Δ'Λ_slab⁻¹Δ = 0.57 (tiny, as expected)
- log_ml = -0.5 × (16.5 + 173.77 + 0.57) = **-95.4**

### Why the Narrow Wins

The narrow component has better log_ml (-91.9 > -95.4) because:

1. **Lower determinant penalty**: log|Σ_n| < log|Λ_slab| (saves 37.6)
2. **Correlation-reduced quadratic form**: Δ'Σ_n⁻¹Δ = 31.12

The slab saves on quadratic form (0.57 vs 31.12 = saves 30.5) but this doesn't overcome the determinant penalty (37.6).

Net: slab is 3.5 worse in log_ml, plus 4.6 from prior weight ratio (ln(0.99/0.01)), giving slab an 8.1 disadvantage in log-odds.

### The Correlation Effect

**With diagonal Σ_n** (what the regression test uses):
```
Δ'Σ_n⁻¹Δ = Σᵢ Δᵢ²/σᵢ²
         = 10366²/7.46e6 + 13156²/7.82e6 + ...
         ≈ 200
```

**With correlated Σ_n** (from bootstrap):
```
Δ'Σ_n⁻¹Δ = 31.12  (6.4× smaller!)
```

High positive correlations create negative off-diagonal terms in Σ_n⁻¹. When Δ has consistent sign (all positive here), these negative terms subtract from the quadratic form, dramatically reducing the penalty.

### Mathematical Intuition

Consider a 2D example with correlation ρ:
```
Σ = σ² × [1, ρ; ρ, 1]
Σ⁻¹ = (1/(σ²(1-ρ²))) × [1, -ρ; -ρ, 1]
```

For Δ = [d, d] (same sign):
```
Δ'Σ⁻¹Δ = (2d²/(σ²(1-ρ²))) × (1 - ρ)
        = (2d²/σ²) × (1-ρ)/(1-ρ²)
        = (2d²/σ²) × 1/(1+ρ)
```

With ρ = 0.77: factor = 1/1.77 = 0.56 (44% reduction)
With ρ = 0: factor = 1 (no reduction)

In 9D with average ρ ≈ 0.5-0.7, the reduction is even more dramatic.

## Comparison: Diagonal vs Correlated

| Quantity | Diagonal Σ_n | Correlated Σ_n |
|----------|--------------|----------------|
| Δ'Σ_n⁻¹Δ | ~200 | ~31 |
| log_ml_narrow | ~-176 | ~-92 |
| log_ml_slab | ~-101 | ~-95 |
| log_ml difference | +75 (slab wins) | -3.5 (narrow wins) |
| Overcomes 99:1 prior? | Yes | No |
| P(leak) | >99% | ~62% |

## Why the Spec Works with Diagonal Covariance

The regression test in `bayes.rs` uses:
```rust
let mut sigma_n = Matrix9::zeros();
for i in 0..9 {
    sigma_n[(i, i)] = ses[i] * ses[i];  // Diagonal only
}
```

This produces P(leak) = 100% because:
1. The quadratic form Δ'Σ_n⁻¹Δ ≈ 200 (full penalty)
2. This overwhelms the determinant advantage of narrow
3. Slab has much better marginal likelihood
4. Slab dominates, posterior tracks data, P(leak) → 1

## The Spec Gap

The v5.2 specification assumes that when effects are large relative to θ, the slab component will have higher marginal likelihood and dominate the posterior. This holds when:

```
(Quadratic form savings) > (Determinant penalty) + (Prior weight penalty)
```

With diagonal Σ_n: ~200 - ~0 > 37 + 4.6 ✓
With correlated Σ_n: ~31 - ~0 < 37 + 4.6 ✗

The spec doesn't account for correlations reducing the effective signal-to-noise ratio in the marginal likelihood computation.

## Potential Fixes

### Option 1: Use Marginal Variances for Weight Computation

Compute component weights using diagonal-only marginal likelihood:
```rust
// For weight computation only (not posterior)
let sigma_n_diag = Matrix9::from_diagonal(&sigma_n.diagonal());
let log_ml_for_weights = compute_marginal_likelihood(delta, &sigma_n_diag, lambda0);
```

This ensures correlations don't artificially boost the narrow component.

### Option 2: Correlation-Adjusted Prior Weights

Adjust the prior weight based on average correlation:
```rust
let avg_corr = compute_average_off_diagonal_correlation(sigma_n);
let adjusted_narrow_weight = 0.99 * (1.0 - avg_corr).powi(2);
// With avg_corr = 0.5: adjusted = 0.99 * 0.25 = 0.25
```

Higher correlations → lower narrow weight → slab can dominate more easily.

### Option 3: Different Slab Scale Formula

Current: σ_slab = max(50θ, 10×SE_med)

The large σ_slab (27,962 ns) creates a huge determinant penalty. Consider:
```rust
// Cap slab scale to limit determinant penalty
let sigma_slab = max(50 * theta, 10 * se_med).min(100 * theta);
```

This keeps the slab "focused" on detecting effects near the threshold.

### Option 4: Bayes Factor with Diagonal Likelihood

Use the full covariance for posterior computation but diagonal for Bayes factor:
```rust
// Posterior uses full covariance (correct uncertainty)
let (delta_post, lambda_post) = compute_posterior(delta, sigma_n, lambda0);

// Bayes factor uses diagonal (correct model comparison)
let bf = compute_bayes_factor_diagonal(delta, sigma_n, lambda0_narrow, lambda0_slab);
```

### Option 5: Empirical Bayes Slab Scale

Set σ_slab based on observed effect magnitude:
```rust
let max_delta = delta.iter().map(|x| x.abs()).fold(0.0, f64::max);
let sigma_slab = max(50 * theta, 3 * max_delta);
```

This is "empirical Bayes" style and may be controversial, but ensures the slab is appropriately scaled for the observed data.

## Recommendation

I suggest **Option 1** (marginal variances for weights) as the primary fix because:

1. It directly addresses the root cause (correlations reducing quadratic form)
2. It preserves proper posterior uncertainty quantification
3. It's conceptually clean: use full covariance for inference, diagonal for model selection
4. It matches the intuition of "penalizing effects by their marginal signal-to-noise"

The posterior computation should still use the full covariance matrix to get correct credible intervals. Only the component weight computation would use diagonal variances.

## Reproduction

To reproduce this issue:

```bash
# Clone SILENT repo with datasets
git clone https://github.com/Icelandic/SILENT /path/to/SILENT

# Run with debug output
TIMING_ORACLE_DEBUG=1 TIMING_ORACLE_DEBUG_ML=1 \
  cargo run --example analyze_silent
```

Look for the "Web Application" section with theta = 100ns.

## Files Referenced

- `crates/timing-oracle-core/src/analysis/bayes.rs`: `compute_bayes_factor_mixture()`, `compute_component_posterior()`
- `crates/timing-oracle-core/src/adaptive/calibration.rs`: `calibrate_narrow_scale()`, `compute_slab_scale()`
- `crates/timing-oracle/src/adaptive/single_pass.rs`: `analyze_single_pass()`
- `crates/timing-oracle/examples/analyze_silent.rs`: Example that demonstrates the issue

## Conclusion

The v5.2 mixture prior correctly handles the case where the likelihood covariance is diagonal (or near-diagonal). However, when the covariance has high inter-decile correlations (common in real bootstrap-estimated data), the narrow component receives an artificial advantage in marginal likelihood, preventing the slab from dominating even when effects are very large.

This is a spec-level issue requiring an amendment to handle correlated covariances properly.
