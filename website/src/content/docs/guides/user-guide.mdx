---
title: User Guide
description: Comprehensive guide to timing side channel detection methodology and usage patterns
sidebar:
  order: 1
---

import { Aside, Tabs, TabItem } from '@astrojs/starlight/components';

This guide provides a comprehensive understanding of timing side channel detection, the statistical methodology behind timing-oracle, and advanced usage patterns.

## The Problem

Timing side channels leak secrets through execution time variations. Classic examples:

```rust
// VULNERABLE: Early-exit comparison
fn compare(a: &[u8], b: &[u8]) -> bool {
    for i in 0..a.len() {
        if a[i] != b[i] {
            return false;  // Exits early on mismatch!
        }
    }
    true
}
```

When comparing a secret against attacker-controlled input, the early exit reveals how many bytes match. An attacker can guess the secret byte-by-byte.

Similar issues affect:
- RSA implementations with non-constant-time modular exponentiation
- AES with table lookups that hit cache differently
- HMAC verification with short-circuit comparison
- Password hashing that exits early on format validation

Existing tools like [dudect](https://github.com/oreparaz/dudect) detect such leaks but have limitations:
- Output t-statistics instead of interpretable probabilities
- Results depend on sample count (more samples → more false positives)
- Miss non-uniform timing effects (e.g., cache-related tail behavior)
- 3.6-8x slower per-sample measurement overhead

---

## DudeCT Two-Class Pattern

This library uses **DudeCT's two-class testing pattern** to detect timing side channels. The goal is to create two input classes where **one triggers slower execution than the other**. If your code has data-dependent timing, the oracle detects this asymmetry.

### The Principle

For a timing leak to be detectable, different inputs must take different amounts of time. The two-class pattern works by choosing inputs that maximize this difference:

- **Baseline class**: Inputs that trigger one timing behavior
- **Sample class**: Inputs that trigger a different timing behavior

If the operation is constant-time, both classes take the same time and no leak is detected.

### Choosing Your Input Classes

The right choice depends on **what causes timing variation** in your operation:

| Leak Type | What Varies | Baseline | Sample |
|-----------|-------------|----------|--------|
| **Branch on bits** | Branches taken for 1-bits vs 0-bits | All zeros (no bits set) | Random (many bits set) |
| **Early-exit comparison** | Iterations until first mismatch | Matches secret (full loop) | Random (exits early) |
| **Cache timing** | Cache hits vs misses | Same indices (cached) | Random indices (misses) |

### Standard Pattern: Zeros vs Random

For most cryptographic operations, **all-zeros vs random** works well:

```rust
use timing_oracle::{TimingOracle, AttackerModel, Outcome, helpers::InputPair};

let inputs = InputPair::new(
    || [0u8; 32],          // Baseline: all zeros
    || rand::random(),     // Sample: random data
);

let outcome = TimingOracle::for_attacker(AttackerModel::AdjacentNetwork)
    .test(inputs, |data| {
        my_crypto_operation(data);
    });
```

This works because zeros are a degenerate case: no bits set, uniform memory access patterns, etc.

### Comparison Functions: Match the Secret

For functions that compare input against a secret, baseline must **match the secret** to create timing asymmetry:

```rust
let secret = [0u8; 32];  // The value being compared against

let inputs = InputPair::new(
    || [0u8; 32],       // Baseline: MATCHES secret → full comparison (slow)
    || rand::random(),  // Sample: mismatches early → exits fast
);

// Test an early-exit comparison (leaky)
let outcome = TimingOracle::for_attacker(AttackerModel::AdjacentNetwork)
    .test(inputs, |data| {
        leaky_compare(&secret, data);
    });
```

<Aside type="caution">
If the secret were `[0x42; 32]` instead, both zeros and random would mismatch on byte 0—no timing difference to detect!
</Aside>

**Rule of thumb**: Ask yourself "What makes this operation take different amounts of time?" Then choose classes that maximize that difference.

---

## How It Works

### Measurement Protocol

1. **Warmup**: Run both operations to stabilize CPU state
2. **Interleaved sampling**: Alternate baseline/sample in randomized order to prevent drift bias
3. **High-precision timing**: Use `rdtsc` (x86) or `cntvct_el0` (ARM) with serialization barriers
4. **Outlier winsorization**: Cap extreme outliers at percentile threshold

### Adaptive Bayesian Analysis

The oracle uses a two-phase adaptive approach:

```
                    Timing Samples
                          │
           ┌──────────────┴──────────────┐
           ▼                             ▼
   ┌───────────────┐           ┌──────────────────┐
   │  Phase 1:     │           │  Phase 2:        │
   │  Calibration  │           │  Adaptive Loop   │
   ├───────────────┤           ├──────────────────┤
   │ 5,000 samples │           │ Batch collection │
   │ Covariance    │           │ Posterior update │
   │ estimation    │           │ Decision check   │
   │ Prior setup   │   ────>   │ Quality gates    │
   │               │           │                  │
   │ Fixed cost    │           │ Stops when       │
   │               │           │ P < 0.05 or      │
   │               │           │ P > 0.95         │
   └───────────────┘           └──────────────────┘
```

**Phase 1 (Calibration)** establishes statistical parameters:
- Estimates noise covariance matrix via block bootstrap
- Computes minimum detectable effect (MDE)
- Sets Bayesian priors from calibration data

**Phase 2 (Adaptive Loop)** collects samples until a decision:
- Collects samples in batches (default 1,000)
- Updates posterior probability after each batch
- Stops when P(leak) < 0.05 (Pass) or P(leak) > 0.95 (Fail)
- Applies quality gates to detect when more data won't help

This adaptive approach:
- **Stops early** on clear pass/fail cases (saves time)
- **Gathers more evidence** when the signal is near the threshold
- **Returns Inconclusive** when hitting resource limits or quality gates

### Quantile-Based Statistics

Rather than comparing means (which miss distributional differences), we compare nine deciles:

```
Baseline class:  [q₁₀, q₂₀, q₃₀, q₄₀, q₅₀, q₆₀, q₇₀, q₈₀, q₉₀]
Sample class:    [q₁₀, q₂₀, q₃₀, q₄₀, q₅₀, q₆₀, q₇₀, q₈₀, q₉₀]
Difference:      Δ ∈ ℝ⁹
```

This captures:
- **Uniform shifts**: Code path takes different branch (affects all quantiles equally)
- **Tail effects**: Cache misses on specific inputs (affects upper quantiles more)

The effect is decomposed using an orthogonalized basis:
```
Δ = μ·[1,1,...,1] + τ·[-0.5, -0.375, ..., 0.375, 0.5] + noise
```

Where μ is the uniform shift and τ is the tail effect.

---

## Timer Selection and Adaptive Batching

### Platform Timers

The library automatically selects the best available timer for your platform:

**x86_64:**
- Uses `rdtsc` instruction (~1ns resolution)
- Cycle-accurate timing without requiring privileges

**macOS ARM64 (Apple Silicon):**
- **Standard Timer** (default): `cntvct_el0` virtual timer (~42ns resolution for M1/M2/M3 at 24 MHz)
- **PmuTimer** (opt-in, requires `sudo`): PMU-based cycle counting (~1ns resolution)

**Linux:**
- **x86_64**: `rdtsc` instruction (~1ns, no privileges needed)
- **ARM64 Standard Timer** (default): `cntvct_el0` virtual timer (resolution varies by SoC)
- **LinuxPerfTimer** (opt-in, requires `sudo`/`CAP_PERFMON`): perf_event cycle counting (~1ns)

### Adaptive Batching

On platforms with coarse timer resolution (>5 ticks per operation), the library automatically enables **adaptive batching**:

1. **Pilot phase**: Measures ~100 warmup iterations to determine median operation time
2. **K selection**: Chooses batch size K to achieve 50+ timer ticks per batch
3. **Batch measurement**: Measures K iterations together and analyzes batch totals
4. **Bounded batching**: Never exceeds K=20 to prevent microarchitectural artifacts

Batching is **automatically disabled** when:
- Timer resolution is fine enough (>5 ticks per call)
- Using `PmuTimer` (macOS) or `LinuxPerfTimer` (Linux)
- Operation is slow enough
- Running on x86_64 (rdtsc provides cycle-accurate timing)

---

## Advanced Examples

### Interpreting Results

```rust
use timing_oracle::{TimingOracle, AttackerModel, Outcome, Exploitability, helpers::InputPair};

let inputs = InputPair::new(|| [0u8; 32], || rand::random());
let outcome = TimingOracle::for_attacker(AttackerModel::AdjacentNetwork)
    .test(inputs, |data| my_function(data));

match outcome {
    Outcome::Pass { leak_probability, quality, .. } => {
        println!("No leak: P(leak)={:.1}%", leak_probability * 100.0);
        println!("Measurement quality: {:?}", quality);
    }

    Outcome::Fail { leak_probability, effect, exploitability, .. } => {
        println!("Leak detected: P(leak)={:.1}%", leak_probability * 100.0);
        println!("Effect breakdown:");
        println!("  Shift: {:.1} ns ({:?})", effect.shift_ns, effect.pattern);
        println!("  Tail:  {:.1} ns", effect.tail_ns);
        println!("  Total: {:.1}-{:.1} ns (95% CI)",
                 effect.credible_interval_ns.0,
                 effect.credible_interval_ns.1);

        // Check exploitability
        match exploitability {
            Exploitability::SharedHardwareOnly =>
                println!("Only exploitable with shared hardware (SGX, containers)"),
            Exploitability::Http2Multiplexing =>
                println!("Exploitable via HTTP/2 request multiplexing (~100k queries)"),
            Exploitability::StandardRemote =>
                println!("Exploitable with standard remote timing (~1k-10k queries)"),
            Exploitability::ObviousLeak =>
                println!("Obvious leak, trivially exploitable (<100 queries)"),
        }
    }

    Outcome::Inconclusive { reason, leak_probability, .. } => {
        println!("Inconclusive: {:?}", reason);
        println!("Current P(leak): {:.1}%", leak_probability * 100.0);
    }

    Outcome::Unmeasurable { recommendation, .. } => {
        println!("Operation too fast: {}", recommendation);
    }
}
```

### Testing Async/Await Code

For async functions, use `Runtime::block_on()` to bridge async → sync for measurement:

```rust
use timing_oracle::{TimingOracle, AttackerModel, Outcome, helpers::InputPair};
use tokio::runtime::Runtime;

// Create a runtime once per test
let rt = tokio::runtime::Builder::new_current_thread()
    .enable_time()
    .build()
    .unwrap();

let inputs = InputPair::new(
    || [0u8; 32],
    || rand::random(),
);

let outcome = TimingOracle::for_attacker(AttackerModel::AdjacentNetwork)
    .test(inputs, |data| {
        rt.block_on(async {
            my_async_crypto_function(data).await;
        })
    });
```

<Aside type="tip" title="Async testing tips">
- Use **single-threaded** runtime for lower noise (`new_current_thread()`)
- Create the runtime **once** outside the measured closures
- Both inputs should perform **identical async operations** for baseline tests
</Aside>

---

## Interpreting Results in Depth

### Understanding Leak Probability

The `leak_probability` is P(max_k |δ_k| > θ_eff | Δ)—the posterior probability that at least one quantile's timing difference exceeds your effective threshold.

| Probability | Interpretation | Outcome |
|-------------|----------------|---------|
| < 5% | Confident no leak | **Pass** |
| 5–50% | Probably safe, uncertain | Inconclusive |
| 50–95% | Probably leaking, uncertain | Inconclusive |
| > 95% | Confident leak | **Fail** |

<Aside>
This is a Bayesian posterior probability, not a frequentist p-value. When we report "72% probability of a leak," we mean: given the data and our model, 72% of the posterior mass corresponds to effects exceeding the threshold.
</Aside>

### Understanding θ_user vs θ_eff vs θ_floor

The library distinguishes between three threshold values:

| Value | Meaning |
|-------|---------|
| θ_user | What you requested (via attacker model) |
| θ_floor | What the measurement could actually resolve |
| θ_eff | What was actually tested: max(θ_user, θ_floor) |

**When θ_eff = θ_user:** Results directly answer "is there a leak > θ_user?"

**When θ_eff > θ_user:** Results answer "is there a leak > θ_eff?" A `Pass` means "no leak above θ_eff," but there could still be a leak between θ_user and θ_eff that wasn't detectable.

### Effect Size and Pattern

The `EffectEstimate` decomposes the timing difference into interpretable components:

**2D Projection:**
- **Shift (μ)**: Uniform timing difference affecting all quantiles equally. Typical cause: different code path, branch on secret bit.
- **Tail (τ)**: Upper quantiles affected more than lower. Typical cause: cache misses, secret-dependent memory access patterns.

**Effect patterns:**

| Pattern | Signature | Typical Cause |
|---------|-----------|---------------|
| UniformShift | μ significant, τ ≈ 0 | Branch on secret bit |
| TailEffect | μ ≈ 0, τ significant | Cache-timing leak |
| Mixed | Both μ and τ significant | Multiple leak sources |
| Complex | Projection mismatch high | Asymmetric or multi-modal |
| Indeterminate | Neither significant | No detectable leak |

### Exploitability Assessment

Risk assessment based on effect size:

| Level | Effect Size | Attack Vector |
|-------|-------------|---------------|
| SharedHardwareOnly | &lt;10 ns | ~1k queries on same physical core |
| Http2Multiplexing | 10–100 ns | ~100k concurrent HTTP/2 requests |
| StandardRemote | 100 ns – 10 μs | ~1k-10k queries with network timing |
| ObviousLeak | &gt;10 μs | &lt;100 queries |

### Handling Inconclusive Results

| Reason | Meaning | Suggested Action |
|--------|---------|------------------|
| DataTooNoisy | Posterior ≈ prior after sampling | Use better timer, reduce system noise |
| NotLearning | KL divergence collapsed | Check for systematic measurement issues |
| WouldTakeTooLong | Projected time exceeds budget | Accept uncertainty or increase budget |
| TimeBudgetExceeded | Ran out of time | Increase `time_budget` |
| SampleBudgetExceeded | Ran out of samples | Increase `max_samples` |
| ConditionsChanged | Calibration assumptions violated | Run in isolation, ensure stable conditions |

---

## Limitations

- **Not a formal proof**: Statistical evidence, not cryptographic verification
- **Noise sensitivity**: High-noise environments may produce unreliable results
- **JIT and optimization**: Ensure test conditions match production
- **Platform-dependent**: Timing characteristics vary across CPUs
- **Exploitability is heuristic**: Actual exploitability depends on conditions

For mission-critical code, combine with formal verification tools like [ct-verif](https://github.com/imdea-software/verifying-constant-time).

---

## References

1. Reparaz, O., Balasch, J., & Verbauwhede, I. (2016). "Dude, is my code constant time?" DATE.
2. Van Goethem, T., et al. (2020). "Timeless Timing Attacks." USENIX Security.
3. Crosby, S. A., Wallach, D. S., & Riedi, R. H. (2009). "Opportunities and limits of remote timing attacks." ACM TISSEC.
